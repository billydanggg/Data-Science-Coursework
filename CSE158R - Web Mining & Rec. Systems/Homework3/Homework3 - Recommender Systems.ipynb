{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "301bf995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "from sklearn import svm\n",
    "import numpy\n",
    "import string\n",
    "import random\n",
    "import string\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31cab31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33f967ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assertFloat(x):\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e25a33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f88efc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        u,b,r = l.strip().split(',')\n",
    "        r = int(r)\n",
    "        yield u,b,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a5f39ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3b16eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some data structures that will be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09ac1dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "allRatings = []\n",
    "for l in readCSV(\"data/train_Interactions.csv.gz\"):\n",
    "    allRatings.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4717806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allRatings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca3c2a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsTrain = allRatings[:190000]\n",
    "ratingsValid = allRatings[190000:]\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "for u,b,r in ratingsTrain:\n",
    "    ratingsPerUser[u].append((b,r))\n",
    "    ratingsPerItem[b].append((u,r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93959f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Read prediction                                #\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "abb17ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from baseline code -> recommendations made based on most popular items \n",
    "bookCount = defaultdict(int)\n",
    "totalRead = 0\n",
    "\n",
    "for user,book,_ in readCSV(\"data/train_Interactions.csv.gz\"):\n",
    "    bookCount[book] += 1\n",
    "    totalRead += 1\n",
    "\n",
    "mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > totalRead/2: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d055731-ab14-4e73-ae36-d21d3ea214be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('u93397390', 'b52690052', 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Personal EDA\n",
    "allRatings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f40789",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b66ab08f-9ff9-4e60-9c71-b0c4ff90ae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a set of all unique books from the training data\n",
    "allBooks = set()\n",
    "for _, book, _ in ratingsTrain:\n",
    "    allBooks.add(book)\n",
    "\n",
    "#for each user in the validation set, create a (user, book) pair with a book that the user has not interacted w/\n",
    "negativeSamples = []\n",
    "for u, b, _ in ratingsValid:\n",
    "    #get the set of books the user has already interacted with\n",
    "    readBooks = set(b for b, _ in ratingsPerUser[u])\n",
    "    #find books the user hasn't read\n",
    "    unreadBooks = list(allBooks - readBooks)\n",
    "    if unreadBooks:\n",
    "        #randomly select a book the user hasn't read as a negative sample\n",
    "        negativeBook = random.choice(unreadBooks)\n",
    "        negativeSamples.append((u, negativeBook))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7c9eea8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the baseline model: 0.7146\n"
     ]
    }
   ],
   "source": [
    "#combine the pos & neg samples and evaluate the accuracy of the baseline model below\n",
    "correctPredictions = 0\n",
    "totalPredictions = 0\n",
    "\n",
    "#check positive samples (true interactions)\n",
    "for u, b, _ in ratingsValid:\n",
    "    if b in return1:  # If the book is in the set of popular books\n",
    "        correctPredictions += 1\n",
    "    totalPredictions += 1\n",
    "\n",
    "#check negative samples (non-interactions)\n",
    "for u, b in negativeSamples:\n",
    "    if b not in return1:  # If the book is not in the set of popular books\n",
    "        correctPredictions += 1\n",
    "    totalPredictions += 1\n",
    "\n",
    "#calculate accuracy\n",
    "accuracy = correctPredictions / totalPredictions\n",
    "print(\"Accuracy of the baseline model:\", accuracy)\n",
    "acc1 = accuracy #.7146"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8af7b181",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q1'] = acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6839df36",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50491907",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "87e03b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold (in terms of totalRead): 0.7\n",
      "Best accuracy of the model with improved threshold: 0.7569\n"
     ]
    }
   ],
   "source": [
    "#initialize variables to track the best threshold and its accuracy\n",
    "bestThreshold = None\n",
    "bestAccuracy = 0\n",
    "\n",
    "#total number of interactions to adjust the threshold (e.g., vary from 10% to 90%)\n",
    "thresholdPercentages = [0.1 * i for i in range(1, 10)]\n",
    "\n",
    "for percentage in thresholdPercentages:\n",
    "    #calculate the threshold based on the percentage of total interactions\n",
    "    currentThreshold = totalRead * percentage\n",
    "\n",
    "    #create the 'popular' book set based on the current threshold\n",
    "    returnSet = set()\n",
    "    count = 0\n",
    "    for ic, i in mostPopular:\n",
    "        count += ic\n",
    "        returnSet.add(i)\n",
    "        if count > currentThreshold:\n",
    "            break\n",
    "\n",
    "    #evaluate the accuracy of the model with the current threshold\n",
    "    correctPredictions = 0\n",
    "    totalPredictions = 0\n",
    "\n",
    "    #check positive samples (true interactions)\n",
    "    for u, b, _ in ratingsValid:\n",
    "        if b in returnSet:  # If the book is in the set of popular books\n",
    "            correctPredictions += 1\n",
    "        totalPredictions += 1\n",
    "\n",
    "    #check negative samples (non-interactions)\n",
    "    for u, b in negativeSamples:\n",
    "        if b not in returnSet:  # If the book is not in the set of popular books\n",
    "            correctPredictions += 1\n",
    "        totalPredictions += 1\n",
    "\n",
    "    #calculate accuracy\n",
    "    accuracy = correctPredictions / totalPredictions\n",
    "\n",
    "    #update the best threshold if the current accuracy is higher\n",
    "    if accuracy > bestAccuracy:\n",
    "        bestAccuracy = accuracy\n",
    "        bestThreshold = currentThreshold\n",
    "\n",
    "print(\"Best threshold (in terms of totalRead):\", bestThreshold / totalRead)\n",
    "print(\"Best accuracy of the model with improved threshold:\", bestAccuracy)\n",
    "threshold = (bestThreshold / totalRead)\n",
    "acc2 = bestAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "263c16a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q2'] = [threshold, acc2] #[.7, .7569]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fcb6b96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q2'][0])\n",
    "assertFloat(answers['Q2'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b753559d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 3/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "04a6f2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Jaccard similarity threshold: 0.003\n",
      "Accuracy of the model with the best Jaccard similarity threshold: 0.70565\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model with different Jaccard similarity thresholds\n",
    "bestThreshold = None\n",
    "bestAccuracy = 0\n",
    "thresholds = [0.001 * i for i in range(1, 15)]  #consider thresholds from 0.001 to 0.015\n",
    "\n",
    "for threshold in thresholds:\n",
    "    correctPredictions = 0\n",
    "    totalPredictions = 0\n",
    "\n",
    "    #check positive samples (true interactions)\n",
    "    for u, b, _ in ratingsValid:\n",
    "        if u not in ratingsPerUser:\n",
    "            #if user is not in the training data, max Jaccard should be 0 (improved model alot)\n",
    "            maxSimilarity = 0\n",
    "        else:\n",
    "            #get the books this user has read in the training data\n",
    "            userBooks = [book for book, _ in ratingsPerUser[u]]\n",
    "            \n",
    "            #compute the maximum Jaccard similarity for this (u, b) pair\n",
    "            maxSimilarity = max((jaccard_similarity(b, b_prime) for b_prime in userBooks), default=0)\n",
    "\n",
    "        #predict 'read' if the maximum similarity exceeds the threshold\n",
    "        if maxSimilarity > threshold:\n",
    "            correctPredictions += 1\n",
    "        totalPredictions += 1\n",
    "\n",
    "    #check negative samples (non-interactions)\n",
    "    for u, b in negativeSamples:\n",
    "        if u not in ratingsPerUser:\n",
    "            #if user is not in the training data, max Jaccard should be 0\n",
    "            maxSimilarity = 0\n",
    "        else:\n",
    "            #get the books this user has read in the training data\n",
    "            userBooks = [book for book, _ in ratingsPerUser[u]]\n",
    "            \n",
    "            #compute the maximum Jaccard similarity for this (u, b) pair\n",
    "            maxSimilarity = max((jaccard_similarity(b, b_prime) for b_prime in userBooks), default=0)\n",
    "\n",
    "        # Predict 'not read' if the maximum similarity does not exceed the threshold\n",
    "        if maxSimilarity <= threshold:\n",
    "            correctPredictions += 1\n",
    "        totalPredictions += 1\n",
    "\n",
    "    accuracy = correctPredictions / totalPredictions\n",
    "\n",
    "    #update the best threshold if the current accuracy is higher\n",
    "    if accuracy > bestAccuracy:\n",
    "        bestAccuracy = accuracy\n",
    "        bestThreshold = threshold\n",
    "\n",
    "# Report the best threshold and its performance\n",
    "print(\"Best Jaccard similarity threshold:\", bestThreshold)\n",
    "print(\"Accuracy of the model with the best Jaccard similarity threshold:\", bestAccuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "30582bdc-7c3a-4115-b8f2-8811851e38c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best popularity threshold (in terms of totalRead): 0.7000000000000001\n",
      "Best Jaccard similarity threshold: 0.1\n",
      "Best accuracy of the combined model: 0.7571\n"
     ]
    }
   ],
   "source": [
    "#initialize variables to track the best combined threshold and its accuracy\n",
    "bestCombinedThresholds = None\n",
    "bestCombinedAccuracy = 0\n",
    "\n",
    "#create the 'popular' book set for a given percentage threshold (e.g., 50% of total interactions)\n",
    "def create_popular_set(percentage):\n",
    "    threshold = totalRead * percentage\n",
    "    popularSet = set()\n",
    "    count = 0\n",
    "    for ic, i in mostPopular:\n",
    "        count += ic\n",
    "        popularSet.add(i)\n",
    "        if count > threshold:\n",
    "            break\n",
    "    return popularSet\n",
    "\n",
    "#define possible threshold values for popularity and Jaccard similarity\n",
    "popularityThresholds = [0.1 * i for i in range(1, 10)]\n",
    "jaccardThresholds = [0.1 * i for i in range(1, 10)]\n",
    "\n",
    "for popThreshold in popularityThresholds:\n",
    "    popularSet = create_popular_set(popThreshold)\n",
    "\n",
    "    for jaccardThreshold in jaccardThresholds:\n",
    "        correctPredictions = 0\n",
    "        totalPredictions = 0\n",
    "\n",
    "        #check positive samples (true interactions)\n",
    "        for u, b, _ in ratingsValid:\n",
    "            if u not in ratingsPerUser:\n",
    "                continue  # Skip users who do not appear in the training data\n",
    "\n",
    "            #get the books this user has read in the training data\n",
    "            userBooks = [book for book, _ in ratingsPerUser[u]]\n",
    "\n",
    "            #compute the maximum Jaccard similarity for this (u, b) pair\n",
    "            maxSimilarity = max((jaccard_similarity(b, b_prime) for b_prime in userBooks), default=0)\n",
    "\n",
    "            #predict 'read' if the book is in the popular set or if the max Jaccard similarity exceeds its threshold\n",
    "            if b in popularSet or maxSimilarity > jaccardThreshold:\n",
    "                correctPredictions += 1\n",
    "            totalPredictions += 1\n",
    "\n",
    "        #evaluate on negative samples\n",
    "        for u, b in negativeSamples:\n",
    "            if u not in ratingsPerUser:\n",
    "                continue  # Skip users who do not appear in the training data\n",
    "\n",
    "            #get the books this user has read in the training data\n",
    "            userBooks = [book for book, _ in ratingsPerUser[u]]\n",
    "\n",
    "            #compute the maximum Jaccard similarity for this (u, b) pair\n",
    "            maxSimilarity = max((jaccard_similarity(b, b_prime) for b_prime in userBooks), default=0)\n",
    "\n",
    "            #predict 'not read' if the book is not in the popular set and the max Jaccard similarity does not exceed its threshold\n",
    "            if b not in popularSet and maxSimilarity <= jaccardThreshold:\n",
    "                correctPredictions += 1\n",
    "            totalPredictions += 1\n",
    "\n",
    "        accuracy = correctPredictions / totalPredictions\n",
    "\n",
    "        #update the best thresholds if the current accuracy is higher\n",
    "        if accuracy > bestCombinedAccuracy:\n",
    "            bestCombinedAccuracy = accuracy\n",
    "            bestCombinedThresholds = (popThreshold, jaccardThreshold)\n",
    "\n",
    "print(\"Best popularity threshold (in terms of totalRead):\", bestCombinedThresholds[0])\n",
    "print(\"Best Jaccard similarity threshold:\", bestCombinedThresholds[1])\n",
    "print(\"Best accuracy of the combined model:\", bestCombinedAccuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "88d59515-b2c3-4bca-ad25-a243abbf268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc3 = bestAccuracy\n",
    "acc4 = bestCombinedAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "83ab0986",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q3'] = acc3\n",
    "answers['Q4'] = acc4 #.7571"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fbdd0c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q3'])\n",
    "assertFloat(answers['Q4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3e68cbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"data/predictions_Read.csv\", 'w')\n",
    "for l in open(\"data/pairs_Read.csv\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,b = l.strip().split(',')\n",
    "    prediction = best_alpha + best_beta_u.get(u, 0) + best_beta_i.get(b, 0)\n",
    "    \n",
    "    # Ensure that the prediction is clipped within a valid range if needed\n",
    "    # For binary classification of 'read' or 'not read', use a threshold\n",
    "    # Here, we'll output '1' if the prediction > 0, otherwise '0'\n",
    "    prediction = 1 if prediction > 0 else 0\n",
    "    \n",
    "    # Write the user, book, and predicted read/not read to the output file\n",
    "    predictions.write(f\"{u},{b},{prediction}\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "297b5c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q5'] = \"I confirm that I have uploaded an assignment submission to gradescope\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b3cb95e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(answers['Q5']) == str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf70975",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Rating prediction                              #\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7f3f37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b960a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6d69e40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 completed.\n",
      "Epoch 20/50 completed.\n",
      "Epoch 30/50 completed.\n",
      "Epoch 40/50 completed.\n",
      "Epoch 50/50 completed.\n",
      "Mean Squared Error on the validation set: 1.4512085358310456\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Split the training data into training and validation sets\n",
    "ratingsTrain = allRatings[:190000]  # First 190,000 for training\n",
    "ratingsValid = allRatings[190000:]  # Last 10,000 for validation\n",
    "\n",
    "# Step 2: Initialize global mean (alpha), user biases (beta_u), and item biases (beta_i)\n",
    "alpha = np.mean([r for _, _, r in ratingsTrain])  # Global mean rating\n",
    "beta_u = defaultdict(float)  # User biases initialized to 0\n",
    "beta_i = defaultdict(float)  # Item biases initialized to 0\n",
    "\n",
    "# Regularization parameter\n",
    "lambda_reg = 1\n",
    "\n",
    "# Step 3: Optimize using gradient descent or coordinate descent\n",
    "num_epochs = 50\n",
    "learning_rate = 0.005\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for u, i, r in ratingsTrain:\n",
    "        # Compute prediction and error\n",
    "        prediction = alpha + beta_u[u] + beta_i[i]\n",
    "        error = r - prediction\n",
    "        \n",
    "        # Update biases using gradient descent\n",
    "        beta_u[u] += learning_rate * (error - lambda_reg * beta_u[u])\n",
    "        beta_i[i] += learning_rate * (error - lambda_reg * beta_i[i])\n",
    "    \n",
    "    # Optional: Print progress every few epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} completed.\")\n",
    "\n",
    "# Step 4: Calculate MSE on the validation set\n",
    "squared_errors = []\n",
    "for u, i, r in ratingsValid:\n",
    "    prediction = alpha + beta_u[u] + beta_i[i]\n",
    "    squared_errors.append((r - prediction) ** 2)\n",
    "\n",
    "mse = np.mean(squared_errors)\n",
    "print(\"Mean Squared Error on the validation set:\", mse)\n",
    "validMSE = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "422ab930",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q6'] = validMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5509bf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9826cdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b6386a18-9c3b-4494-a1a3-f2f43b2d6cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User with the largest beta_u:\n",
      "User ID: u54484760, Beta value: 0.7398267605352622\n",
      "\n",
      "User with the smallest (most negative) beta_u:\n",
      "User ID: u66752856, Beta value: -1.867137549496119\n"
     ]
    }
   ],
   "source": [
    "#find the user with the largest beta_u value\n",
    "maxUser = str(max(beta_u, key=beta_u.get))\n",
    "maxBeta = float(beta_u[maxUser])\n",
    "\n",
    "#find the user with the smallest (most negative) beta_u value\n",
    "minUser = str(min(beta_u, key=beta_u.get))\n",
    "minBeta = float(beta_u[minUser])\n",
    "\n",
    "print(\"User with the largest beta_u:\")\n",
    "print(f\"User ID: {maxUser}, Beta value: {maxBeta}\")\n",
    "\n",
    "print(\"\\nUser with the smallest (most negative) beta_u:\")\n",
    "print(f\"User ID: {minUser}, Beta value: {minBeta}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c61b675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q7'] = [maxUser, minUser, maxBeta, minBeta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7aca2bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert [type(x) for x in answers['Q7']] == [str, str, float, float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a416949",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ae54cf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 0.1, MSE: 1.421040047749516\n",
      "Lambda: 0.5, MSE: 1.4236590936155058\n",
      "Lambda: 1, MSE: 1.4512085358310456\n",
      "Lambda: 2, MSE: 1.5058484967465937\n",
      "Lambda: 5, MSE: 1.5953736843719877\n",
      "Lambda: 10, MSE: 1.649831254023476\n",
      "\n",
      "Best Lambda: 0.1\n",
      "Valid MSE on the validation set with the best lambda: 1.421040047749516\n"
     ]
    }
   ],
   "source": [
    "#define a function to train the model with a given lambda and calculate the MSE\n",
    "def train_model(lambda_reg, num_epochs=50, learning_rate=0.005):\n",
    "    alpha = np.mean([r for _, _, r in ratingsTrain])  # Global mean rating\n",
    "    beta_u = defaultdict(float)  # User biases initialized to 0\n",
    "    beta_i = defaultdict(float)  # Item biases initialized to 0\n",
    "\n",
    "    #training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        for u, i, r in ratingsTrain:\n",
    "            # Compute prediction and error\n",
    "            prediction = alpha + beta_u[u] + beta_i[i]\n",
    "            error = r - prediction\n",
    "\n",
    "            # Update biases using gradient descent with regularization\n",
    "            beta_u[u] += learning_rate * (error - lambda_reg * beta_u[u])\n",
    "            beta_i[i] += learning_rate * (error - lambda_reg * beta_i[i])\n",
    "\n",
    "    # Calculate MSE on the validation set\n",
    "    squared_errors = []\n",
    "    for u, i, r in ratingsValid:\n",
    "        prediction = alpha + beta_u[u] + beta_i[i]\n",
    "        squared_errors.append((r - prediction) ** 2)\n",
    "\n",
    "    mse = np.mean(squared_errors)\n",
    "    return mse, alpha, beta_u, beta_i\n",
    "\n",
    "# Step 3: Try different values of lambda and find the best one\n",
    "lambda_values = [0.1, 0.5, 1, 2, 5, 10]\n",
    "best_lambda = None\n",
    "best_mse = float('inf')\n",
    "best_alpha = None\n",
    "best_beta_u = None\n",
    "best_beta_i = None\n",
    "\n",
    "for lambda_reg in lambda_values:\n",
    "    mse, alpha, beta_u, beta_i = train_model(lambda_reg)\n",
    "    print(f\"Lambda: {lambda_reg}, MSE: {mse}\")\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_lambda = lambda_reg\n",
    "        best_alpha = alpha\n",
    "        best_beta_u = beta_u\n",
    "        best_beta_i = beta_i\n",
    "\n",
    "lamb = best_lambda\n",
    "validMSE = best_mse\n",
    "print(\"\\nBest Lambda:\", best_lambda)\n",
    "print(\"Valid MSE on the validation set with the best lambda:\", best_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f1880fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q8'] = (lamb, validMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "56b09160",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q8'][0])\n",
    "assertFloat(answers['Q8'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b9bd53b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"data/predictions_Rating.csv\", 'w')\n",
    "for l in open(\"data/pairs_Rating.csv\"):\n",
    "    if l.startswith(\"userID\"): # header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u, b = l.strip().split(',')\n",
    "    \n",
    "    # Make the prediction using the best alpha, beta_u, and beta_i values\n",
    "    prediction = best_alpha + best_beta_u[u] + best_beta_i[b]\n",
    "    \n",
    "    # Clip the prediction to a valid rating range if necessary (e.g., between 1 and 5)\n",
    "    prediction = max(1, min(5, prediction))\n",
    "    \n",
    "    # Write the user, book, and predicted rating to the output file\n",
    "    predictions.write(f\"{u},{b},{prediction}\\n\")\n",
    "    \n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "839261ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"answers_hw3.txt\", 'w')\n",
    "f.write(str(answers) + '\\n')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
