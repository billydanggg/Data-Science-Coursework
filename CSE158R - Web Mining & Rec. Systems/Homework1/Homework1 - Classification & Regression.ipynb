{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "d545425e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import random\n",
    "import gzip\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "d577aff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "e74ac91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assertFloat(x): # Checks that an answer is a float\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "1a7911bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = gzip.open(\"data/young_adult_10000.json.gz\")\n",
    "dataset = []\n",
    "for l in f:\n",
    "    dataset.append(json.loads(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "85100ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "e716aa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {} # Put your answers to each question in this dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "cb2c286a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': '8842281e1d1347389f2ab93d60773d4d',\n",
       " 'book_id': '2767052',\n",
       " 'review_id': '248c011811e945eca861b5c31a549291',\n",
       " 'rating': 5,\n",
       " 'review_text': \"I cracked and finally picked this up. Very enjoyable quick read - couldn't put it down - it was like crack. \\n I'm a bit bothered by the lack of backstory of how Panem and the Hunger Games come about. It is just kind of explained away in a few paragraphs and we are left to accept this very strange world where teenagers are pitted into an arena each year to kill each other? I was expecting it because I've seen Battle Royale, but I would have appreciated knowing more of the backstory of how the world could have come into such a odd state. \\n I suppose what makes a book like this interesting is thinking about the strategy of it all. The players are going to be statistically encouraged to band together because they will last longer that way, but by definition of course any partnership will be broken, and the drama of how that unfolds is always interesting and full of friendships broken and betrayal. Each character approached the game in their own way. Some banded together in larger coalitions, some were loners initially and banded together later. And some were just loners, like Foxface. A lot depended on your survival skill: could you find food and water on your own? Self-dependence is highly valued - and of course our hero was strong there. \\n All in all, a fun read, but I feel kind of dirty for having read it.\",\n",
       " 'date_added': 'Wed Jan 13 13:38:25 -0800 2010',\n",
       " 'date_updated': 'Wed Mar 22 11:46:36 -0700 2017',\n",
       " 'read_at': 'Sun Mar 25 00:00:00 -0700 2012',\n",
       " 'started_at': 'Fri Mar 23 00:00:00 -0700 2012',\n",
       " 'n_votes': 24,\n",
       " 'n_comments': 25}"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "2a260695",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "fea5f8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "    #Won't use\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "c6950994-220f-4bab-85c1-b3d32d7daa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting target variable\n",
    "ratings_list = [review['rating'] for review in dataset]\n",
    "\n",
    "#Extracting exclamation mark feature\n",
    "mark_list = []\n",
    "for review in dataset:\n",
    "    if 'review_text' in review:\n",
    "        mark_count = review['review_text'].count('!')\n",
    "        mark_list.append(mark_count)\n",
    "mark_df = pd.DataFrame(mark_list, columns = ['Marks'])\n",
    "ratings_df = pd.DataFrame(ratings_list, columns = ['Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "8f00dea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mark_df\n",
    "Y = ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "84b3268e-b5ba-4fe7-9fb1-7d8b4229f565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building model\n",
    "model_1 = LinearRegression()\n",
    "model_1.fit(X, Y)\n",
    "\n",
    "#Grabbing theta values & MSE\n",
    "theta0 = model_1.intercept_[0]\n",
    "theta1 = (model_1.coef_[0])[0]\n",
    "y_pred = model_1.predict(X)\n",
    "mse = mean_squared_error(Y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "51581a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q1'] = [theta0, theta1, mse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "525fd954",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q1'], 3) # Check the format of your answer (three floats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "8b84731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "982ea2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "    #Won't use\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "ac825224-e03b-4235-88db-b14dc0f67277",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract feature (length) from JSON file\n",
    "len_list = [len(review['review_text']) for review in dataset]\n",
    "\n",
    "#Create dataframe for model (rather than making into matrix)\n",
    "features_df = pd.DataFrame({'Length': len_list, 'Marks': mark_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "cda70702",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features_df\n",
    "Y = ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "3d3f22d8-cd1f-4529-ab77-e6266f6f4544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build out model\n",
    "model_2 = LinearRegression()\n",
    "model_2.fit(X, Y)\n",
    "\n",
    "#Grabbing theta values & MSE \n",
    "#(includes [0/1] since .intercept_ & .coef_ return an array)\n",
    "\n",
    "theta0 = model_2.intercept_[0]\n",
    "theta1 = (model_2.coef_[0])[0]\n",
    "theta2 = (model_2.coef_[0])[1]\n",
    "y_pred = model_2.predict(X)\n",
    "mse = mean_squared_error(Y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "f099afd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q2'] = [theta0, theta1, theta2, mse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "31e2f9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q2'], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "1147c4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "78ef0f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum, deg):\n",
    "    # feature for a specific polynomial degree\n",
    "    #Won't use\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "7ab7e5e0-5965-4341-8549-97d2cbae186f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating feature dataframes for models\n",
    "mark_df_2 = mark_df.copy()\n",
    "mark_df_2['Marks_2'] = mark_df['Marks'] ** 2\n",
    "\n",
    "mark_df_3 = mark_df_2.copy()\n",
    "mark_df_3['Marks_3'] = mark_df['Marks'] ** 3\n",
    "\n",
    "mark_df_4 = mark_df_3.copy()\n",
    "mark_df_4['Marks_4'] = mark_df['Marks'] ** 4\n",
    "\n",
    "mark_df_5 = mark_df_4.copy()\n",
    "mark_df_5['Marks_5'] = mark_df['Marks'] ** 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "ba009b8c-e037-4ded-b37f-42d9e4d25a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.5231747404538287,\n",
       " 1.5046686106250917,\n",
       " 1.496684551517923,\n",
       " 1.490447730223069,\n",
       " 1.4896106953961645]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mses = []\n",
    "model_3 = LinearRegression()\n",
    "\n",
    "#Model Degree 1 (same as Model_1)\n",
    "model_3.fit(mark_df, Y)\n",
    "y_pred = model_3.predict(mark_df)\n",
    "mses.append(mean_squared_error(Y, y_pred))\n",
    "\n",
    "#Model Degree 2 \n",
    "model_3.fit(mark_df_2, Y)\n",
    "y_pred = model_3.predict(mark_df_2)\n",
    "mses.append(mean_squared_error(Y, y_pred))\n",
    "\n",
    "#Model Degree 3\n",
    "model_3.fit(mark_df_3, Y)\n",
    "y_pred = model_3.predict(mark_df_3)\n",
    "mses.append(mean_squared_error(Y, y_pred))\n",
    "\n",
    "#Model Degree 4\n",
    "model_3.fit(mark_df_4, Y)\n",
    "y_pred = model_3.predict(mark_df_4)\n",
    "mses.append(mean_squared_error(Y, y_pred))\n",
    "\n",
    "#Model Degree 5\n",
    "model_3.fit(mark_df_5, Y)\n",
    "y_pred = model_3.predict(mark_df_5)\n",
    "mses.append(mean_squared_error(Y, y_pred))\n",
    "\n",
    "mses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "559faac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q3'] = mses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "bbb5da71",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q3'], 5)# List of length 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "dcbb8263",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "e91bc048",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_4 = LinearRegression()\n",
    "\n",
    "mark_df['Rating'] = ratings_df\n",
    "mid = len(mark_df)//2\n",
    "\n",
    "training = mark_df.iloc[:mid]\n",
    "X_train = training[['Marks']]\n",
    "Y_train = training[['Rating']]\n",
    "\n",
    "testing = mark_df.iloc[mid:]\n",
    "X_test = testing[['Marks']]\n",
    "Y_test = testing[['Rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "13c7a459-6744-4964-b217-40c273c9a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating feature dataframes for models\n",
    "training_df_2 = X_train.copy()\n",
    "testing_df_2 = X_test.copy()\n",
    "\n",
    "#Model2\n",
    "training_df_2['Marks_2'] = training_df_2['Marks'] ** 2\n",
    "testing_df_2['Marks_2'] = testing_df_2['Marks'] ** 2 \n",
    "\n",
    "#Model3\n",
    "training_df_3 = training_df_2.copy()\n",
    "testing_df_3 = testing_df_2.copy()\n",
    "training_df_3['Marks_3'] = training_df_3['Marks'] ** 3\n",
    "testing_df_3['Marks_3'] = testing_df_3['Marks'] ** 3 \n",
    "\n",
    "#Model4\n",
    "training_df_4 = training_df_3.copy()\n",
    "testing_df_4 = testing_df_3.copy()\n",
    "training_df_4['Marks_4'] = training_df_4['Marks'] ** 4\n",
    "testing_df_4['Marks_4'] = testing_df_4['Marks'] ** 4\n",
    "\n",
    "#Model5\n",
    "training_df_5 = training_df_4.copy()\n",
    "testing_df_5 = testing_df_4.copy()\n",
    "training_df_5['Marks_5'] = training_df_5['Marks'] ** 5\n",
    "testing_df_5['Marks_5'] = testing_df_5['Marks'] ** 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "42f993ec-a3d4-4c43-8452-b6e15ed2cb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = LinearRegression()\n",
    "mses = []\n",
    "\n",
    "#order 1\n",
    "model_4.fit(X_train, Y_train)\n",
    "y_pred = model_4.predict(X_test)\n",
    "mses.append(mean_squared_error(Y_test, y_pred))\n",
    "\n",
    "#order2\n",
    "model_4.fit(training_df_2, Y_train)\n",
    "y_pred = model_4.predict(testing_df_2)\n",
    "mses.append(mean_squared_error(Y_test, y_pred))\n",
    "\n",
    "#order3\n",
    "model_4.fit(training_df_3, Y_train)\n",
    "y_pred = model_4.predict(testing_df_3)\n",
    "mses.append(mean_squared_error(Y_test, y_pred))\n",
    "\n",
    "#order4\n",
    "model_4.fit(training_df_4, Y_train)\n",
    "y_pred = model_4.predict(testing_df_4)\n",
    "mses.append(mean_squared_error(Y_test, y_pred))\n",
    "\n",
    "#order5\n",
    "model_4.fit(training_df_5, Y_train)\n",
    "y_pred = model_4.predict(testing_df_5)\n",
    "mses.append(mean_squared_error(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "fdd505ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q4'] = mses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "d2954061",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q4'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "2fa286a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "81dcc36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The best predictor in terms of the MAE is the median\n",
    "theta0 = np.median(Y_train)\n",
    "y_pred = np.full_like(Y_test, theta0)\n",
    "\n",
    "mae = mean_absolute_error(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "b3a2e9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q5'] = mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "d71a47ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "cf84f30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "19b5b795",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"data/beer_50000.json\")\n",
    "dataset = []\n",
    "for l in f:\n",
    "    if 'user/gender' in l: #only appends recoreds with gender specified\n",
    "        dataset.append(eval(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "299d4fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20403"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "986aa481-c225-4c08-aa14-946a970aab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[1, d['review/text'].count('!')] for d in dataset]\n",
    "y = [d['user/gender'] == 'Female' for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "820c4352-8daf-4fcc-a8ff-0ae47d5ecaae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5 = LogisticRegression()\n",
    "model_5.fit(X, y)\n",
    "y_pred = model_5.predict(X) #binary vector of predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "974c5925-3f2f-4753-a6c1-07312176db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel() #ravel() lays matrix out into 1D array\n",
    "\n",
    "fpr = fp / (fp + tn) if (fp + tn) != 0 else 0\n",
    "fnr = fn / (fn + tp) if (fn + tp) != 0 else 0\n",
    "ber = (fpr + fnr) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "0ad92d32-ece5-4e19-8f47-4faef0fe5ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = tp\n",
    "TN = tn\n",
    "FP = fp\n",
    "FN = fn\n",
    "BER = ber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "0c35d20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q6'] = [TP, TN, FP, FN, BER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "9b18991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q6'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f066f3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "d24c241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6 = LogisticRegression(class_weight = 'balanced')\n",
    "model_6.fit(X, y)\n",
    "y_pred = model_6.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "53979e69-1399-4779-8b68-532e1d33dd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel() #ravel() lays matrix out into 1D array\n",
    "\n",
    "fpr = fp / (fp + tn) if (fp + tn) != 0 else 0\n",
    "fnr = fn / (fn + tp) if (fn + tp) != 0 else 0\n",
    "ber = (fpr + fnr) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "6a37167c-0b50-4f9b-b79f-33d49dfffec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = tp\n",
    "TN = tn\n",
    "FP = fp\n",
    "FN = fn\n",
    "BER = ber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "0622704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers[\"Q7\"] = [TP, TN, FP, FN, BER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "efb03c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q7'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e622c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "9b6bcea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = [1, 10, 100, 1000, 10000]\n",
    "precisionList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "7e2f0680-93ee-45f2-8daf-b1ae596735fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We may only have a fixed budget of results taht can be returned to a user and we might be\n",
    "#interested in evaluating the precision and recall when our classifier returns only its K most\n",
    "#confident predictions.\n",
    "\n",
    "confidences = model_6.decision_function(X) #real vector of confidences \n",
    "\n",
    "sortedByConfidence = list(zip(confidences, y))\n",
    "sortedByConfidence.sort(reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "274b3b98-cc1c-4c4f-87ad-ecfe8dc1a9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(0, len(k_values)):\n",
    "    retrievedLabels = [x[1] for x in sortedByConfidence[:k_values[index]]]\n",
    "    precisionK = sum( retrievedLabels ) / len( retrievedLabels )\n",
    "    precisionList.append(precisionK)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "764513e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q8'] = precisionList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "b0d7d87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q8'], 5) #List of five floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "d557ab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"answers_hw1.txt\", 'w') # Write your answers to a file\n",
    "f.write(str(answers) + '\\n')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
