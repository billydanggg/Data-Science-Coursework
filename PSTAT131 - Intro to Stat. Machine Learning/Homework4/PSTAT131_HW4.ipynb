{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a6e3420-b465-446e-a580-386f5bf73b60",
   "metadata": {},
   "source": [
    "# Homework 4\n",
    "### PSTAT 131"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c2c919-62d7-4d2e-985d-beed5cb45441",
   "metadata": {},
   "source": [
    "## Resampling\n",
    "For this assignment, we will be working with **two** of our previous data sets - one for classification and one for regression. For the classification problem, our goal is (once again) to predict which passengers would survive the Titanic shipwreck. For the regression problem, our goal is (also once again) to predict abalone age.\n",
    "\n",
    "Loead the data from data/titanic.csv and data/abalone.csv into Python and refresh your memory about the variables they contain using their attached codebooks.\n",
    "\n",
    "Make sure to change survived and pclass to factors, as before, and make sure to generate the age variable as rings + 1.5!\n",
    "\n",
    "*Remember that you'll need to set a seed at the beginning of the document to repoduce your results.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59f3f2cb-d8ff-4ecf-8ad9-62fd942b4c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b58830a-bc60-4a8a-a941-f8dc648b271a",
   "metadata": {},
   "source": [
    "### Section 1: Regression (abalone age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320c147a-8fea-4627-a577-cab63270af6a",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "Follow the instructions from Homework 2 to split the data set, stratifying on the outcome variable, age. You can choose the proportions to split the data into. Use k-fold cross-validation to create 5 folds from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b587f89c-c6e3-4292-868e-d94315c2a992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9ed1baf-9f93-42f0-b8b7-049a6f0bb161",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in the datasets\n",
    "abalone_data = pd.read_csv(\"data/abalone.csv\")\n",
    "\n",
    "#Add age target variable\n",
    "abalone_data[\"age\"] = abalone_data[\"rings\"] + 1.5\n",
    "\n",
    "#Dropping 'rings' feature due to structural collinearity\n",
    "abalone_data = abalone_data.drop(\"rings\", axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5c6cef0-72e8-4bdb-80ec-681a4bc73679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>longest_shell</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.15</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  type  longest_shell  diameter  height  whole_weight  shucked_weight  \\\n",
       "0    M          0.455     0.365   0.095         0.514          0.2245   \n",
       "\n",
       "   viscera_weight  shell_weight   age  \n",
       "0           0.101          0.15  16.5  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check appropriate changes were made \n",
    "abalone_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1a424f1-722e-4d6b-855c-8931b86bad96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split features and target variable\n",
    "X = abalone_data.drop(\"age\", axis = 1)\n",
    "y = abalone_data[\"age\"]\n",
    "\n",
    "#Create quantiles bins for stratified sampling \n",
    "age_binned = pd.qcut(y, q = 4, labels = False)\n",
    "\n",
    "#Split train/test data w/ stratified sampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = age_binned, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b282795-862a-4179-a809-4fca83398d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longest_shell</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>type_F</th>\n",
       "      <th>type_I</th>\n",
       "      <th>type_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3951</th>\n",
       "      <td>0.465</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.6355</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>0.1570</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>0.630</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.1720</td>\n",
       "      <td>0.5360</td>\n",
       "      <td>0.2540</td>\n",
       "      <td>0.3160</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3257</th>\n",
       "      <td>0.505</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.6550</td>\n",
       "      <td>0.3185</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1850</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>0.525</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.8435</td>\n",
       "      <td>0.4325</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.560</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1.0235</td>\n",
       "      <td>0.4290</td>\n",
       "      <td>0.2680</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>0.335</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.1665</td>\n",
       "      <td>0.0595</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>0.370</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2545</td>\n",
       "      <td>0.1080</td>\n",
       "      <td>0.0565</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>0.505</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.7750</td>\n",
       "      <td>0.3445</td>\n",
       "      <td>0.1570</td>\n",
       "      <td>0.1850</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>0.405</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.3185</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>0.0905</td>\n",
       "      <td>0.0950</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>0.450</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.4780</td>\n",
       "      <td>0.1865</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3341 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      longest_shell  diameter  height  whole_weight  shucked_weight  \\\n",
       "3951          0.465     0.390   0.110        0.6355          0.1815   \n",
       "3423          0.630     0.475   0.150        1.1720          0.5360   \n",
       "3257          0.505     0.385   0.110        0.6550          0.3185   \n",
       "2830          0.525     0.430   0.135        0.8435          0.4325   \n",
       "182           0.560     0.450   0.160        1.0235          0.4290   \n",
       "...             ...       ...     ...           ...             ...   \n",
       "651           0.335     0.245   0.090        0.1665          0.0595   \n",
       "2555          0.370     0.290   0.080        0.2545          0.1080   \n",
       "3727          0.505     0.400   0.150        0.7750          0.3445   \n",
       "805           0.405     0.305   0.120        0.3185          0.1235   \n",
       "3198          0.450     0.335   0.140        0.4780          0.1865   \n",
       "\n",
       "      viscera_weight  shell_weight  type_F  type_I  type_M  \n",
       "3951          0.1570        0.2250       1       0       0  \n",
       "3423          0.2540        0.3160       1       0       0  \n",
       "3257          0.1500        0.1850       0       0       1  \n",
       "2830          0.1800        0.1815       1       0       0  \n",
       "182           0.2680        0.3000       1       0       0  \n",
       "...              ...           ...     ...     ...     ...  \n",
       "651           0.0400        0.0600       0       1       0  \n",
       "2555          0.0565        0.0700       0       1       0  \n",
       "3727          0.1570        0.1850       0       0       1  \n",
       "805           0.0905        0.0950       0       0       1  \n",
       "3198          0.1150        0.1600       0       0       1  \n",
       "\n",
       "[3341 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dummy code any categorical predictors\n",
    "coded_X_train = pd.get_dummies(X_train, columns = ['type'])\n",
    "coded_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "baa35a3c-428c-4d46-bcb2-c23a40fa7fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longest_shell</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>type_F</th>\n",
       "      <th>type_I</th>\n",
       "      <th>type_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.485566</td>\n",
       "      <td>-0.176117</td>\n",
       "      <td>-0.686432</td>\n",
       "      <td>-0.387921</td>\n",
       "      <td>-0.792995</td>\n",
       "      <td>-0.208390</td>\n",
       "      <td>-0.097979</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>-0.695866</td>\n",
       "      <td>-0.759889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.883863</td>\n",
       "      <td>0.677664</td>\n",
       "      <td>0.249637</td>\n",
       "      <td>0.701865</td>\n",
       "      <td>0.800942</td>\n",
       "      <td>0.672978</td>\n",
       "      <td>0.550822</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>-0.695866</td>\n",
       "      <td>-0.759889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.153583</td>\n",
       "      <td>-0.226339</td>\n",
       "      <td>-0.686432</td>\n",
       "      <td>-0.348311</td>\n",
       "      <td>-0.177002</td>\n",
       "      <td>-0.271994</td>\n",
       "      <td>-0.383166</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.695866</td>\n",
       "      <td>1.315981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012408</td>\n",
       "      <td>0.225663</td>\n",
       "      <td>-0.101389</td>\n",
       "      <td>0.034587</td>\n",
       "      <td>0.335576</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>-0.408120</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>-0.695866</td>\n",
       "      <td>-0.759889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.302893</td>\n",
       "      <td>0.426552</td>\n",
       "      <td>0.483654</td>\n",
       "      <td>0.400219</td>\n",
       "      <td>0.319839</td>\n",
       "      <td>0.800186</td>\n",
       "      <td>0.436747</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>-0.695866</td>\n",
       "      <td>-0.759889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3336</th>\n",
       "      <td>-1.564510</td>\n",
       "      <td>-1.632567</td>\n",
       "      <td>-1.154467</td>\n",
       "      <td>-1.340596</td>\n",
       "      <td>-1.341543</td>\n",
       "      <td>-1.271484</td>\n",
       "      <td>-1.274376</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>1.437059</td>\n",
       "      <td>-0.759889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3337</th>\n",
       "      <td>-1.274025</td>\n",
       "      <td>-1.180565</td>\n",
       "      <td>-1.388484</td>\n",
       "      <td>-1.161842</td>\n",
       "      <td>-1.123472</td>\n",
       "      <td>-1.121560</td>\n",
       "      <td>-1.203079</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>1.437059</td>\n",
       "      <td>-0.759889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3338</th>\n",
       "      <td>-0.153583</td>\n",
       "      <td>-0.075672</td>\n",
       "      <td>0.249637</td>\n",
       "      <td>-0.104557</td>\n",
       "      <td>-0.060098</td>\n",
       "      <td>-0.208390</td>\n",
       "      <td>-0.383166</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.695866</td>\n",
       "      <td>1.315981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3339</th>\n",
       "      <td>-0.983540</td>\n",
       "      <td>-1.029898</td>\n",
       "      <td>-0.452415</td>\n",
       "      <td>-1.031840</td>\n",
       "      <td>-1.053780</td>\n",
       "      <td>-0.812627</td>\n",
       "      <td>-1.024837</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.695866</td>\n",
       "      <td>1.315981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3340</th>\n",
       "      <td>-0.610059</td>\n",
       "      <td>-0.728563</td>\n",
       "      <td>0.015620</td>\n",
       "      <td>-0.707849</td>\n",
       "      <td>-0.770513</td>\n",
       "      <td>-0.590013</td>\n",
       "      <td>-0.561408</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.695866</td>\n",
       "      <td>1.315981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3341 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      longest_shell  diameter    height  whole_weight  shucked_weight  \\\n",
       "0         -0.485566 -0.176117 -0.686432     -0.387921       -0.792995   \n",
       "1          0.883863  0.677664  0.249637      0.701865        0.800942   \n",
       "2         -0.153583 -0.226339 -0.686432     -0.348311       -0.177002   \n",
       "3          0.012408  0.225663 -0.101389      0.034587        0.335576   \n",
       "4          0.302893  0.426552  0.483654      0.400219        0.319839   \n",
       "...             ...       ...       ...           ...             ...   \n",
       "3336      -1.564510 -1.632567 -1.154467     -1.340596       -1.341543   \n",
       "3337      -1.274025 -1.180565 -1.388484     -1.161842       -1.123472   \n",
       "3338      -0.153583 -0.075672  0.249637     -0.104557       -0.060098   \n",
       "3339      -0.983540 -1.029898 -0.452415     -1.031840       -1.053780   \n",
       "3340      -0.610059 -0.728563  0.015620     -0.707849       -0.770513   \n",
       "\n",
       "      viscera_weight  shell_weight    type_F    type_I    type_M  \n",
       "0          -0.208390     -0.097979  1.500000 -0.695866 -0.759889  \n",
       "1           0.672978      0.550822  1.500000 -0.695866 -0.759889  \n",
       "2          -0.271994     -0.383166 -0.666667 -0.695866  1.315981  \n",
       "3           0.000594     -0.408120  1.500000 -0.695866 -0.759889  \n",
       "4           0.800186      0.436747  1.500000 -0.695866 -0.759889  \n",
       "...              ...           ...       ...       ...       ...  \n",
       "3336       -1.271484     -1.274376 -0.666667  1.437059 -0.759889  \n",
       "3337       -1.121560     -1.203079 -0.666667  1.437059 -0.759889  \n",
       "3338       -0.208390     -0.383166 -0.666667 -0.695866  1.315981  \n",
       "3339       -0.812627     -1.024837 -0.666667 -0.695866  1.315981  \n",
       "3340       -0.590013     -0.561408 -0.666667 -0.695866  1.315981  \n",
       "\n",
       "[3341 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Centering & Scaling all predictors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "cols = coded_X_train.columns\n",
    "X_train_scaled = sc.fit_transform(coded_X_train)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns = cols)\n",
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05344c52-70cd-4714-9c68-fcba1d096023",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying changes to testing set for later evaluation\n",
    "coded_X_test = pd.get_dummies(X_test, columns = ['type'])\n",
    "\n",
    "cols_x = coded_X_test.columns\n",
    "\n",
    "X_test_scaled = sc.fit_transform(coded_X_test)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns = cols_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfca0fa7-b7db-46bc-a652-05272be11899",
   "metadata": {},
   "source": [
    "> We'll use GridSearchCV(cv = 5) during our model tuning / evaluation step to run k-fold cross validation instead of splitting it now (easier and cleaner code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628c8810-6ea8-491f-b0d7-597344939754",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "In your own words, explain what we are doing when we perform k-fold cross-validation:\n",
    "- What is k-fold cross-validation?\n",
    "- Why should we use it, rather than simply comparing our model results on the entire training set?\n",
    "- If we split the training set into two and used one of those two splits to evaluate/compare our models, what resampling method would we be using?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678e3d75-3841-4034-96e9-07ad5bd5f47d",
   "metadata": {},
   "source": [
    "> K-fold cross validation provides the user with a way to validate/predict the approximate performance of their machine learning models by splitting the training data set further in \"K\" folds, fitting the model to one of those folds, and testing on the rest (k-1 folds). This process is then repeated k times. Performing k-fold cross validation helps ensure that the model can generalize well to new data, and prevents data leakage & overfitting (which would happen if we use the entire training set as a means of validation). Splitting the training set into two and using one of the two splits to evaluate/compare our models is called validation set sampling. While it is the simplest way to do resampling, it is less robust to overfitting and leads to less data to train your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47f7a4b-ddbe-4e46-82fa-f97d14182d24",
   "metadata": {},
   "source": [
    "#### Question 3 \n",
    "Set up the three models:\n",
    "- K-nearest Neighbors with the KNeighborsRegressor function, tuning n_neighbors\n",
    "- linear regression\n",
    "- elastic net linear regression, tuning penalty and mixture\n",
    "\n",
    "Use GridSearchCV to set up grids of values for all of the parameters we're tuning. Use values of neighbors from 1 to 10, the default values of penalty, and values of mixture from 0 to 1. Set up 10 levels of each.\n",
    "\n",
    "How many models total, **across all folds**, will we be fitting ot the abalone data? To answer, think about how many folds there are, how many combinations of model parameters there are, and how many models you'll fit to each fold.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45846abf-be23-4f64-be4b-24593ba4c562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Define model & tuning grid\n",
    "knn_model = KNeighborsRegressor()\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': range(1,11)\n",
    "}\n",
    "#Evaluate w/ 5-fold CV\n",
    "grid_search_mae_knn = GridSearchCV(knn_model, param_grid_knn, cv = 5, scoring = 'neg_root_mean_squared_error')\n",
    "grid_search_mae_knn.fit(X_train_scaled, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "128ebd94-edee-45cc-b9a2-15326ee48e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#Define the model\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "#Evaluate w/ 5-fold CV\n",
    "neg_rmse_cv_scores_lr = cross_val_score(lr_model, X_train_scaled, y_train, cv = 5, scoring = 'neg_root_mean_squared_error')\n",
    "\n",
    "#Turn - into +\n",
    "rmse_cv_scores_lr = -neg_rmse_cv_scores_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f502021-efd5-44c3-8fa8-58e525f44fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "#Define the model & tuning grid\n",
    "en_model = ElasticNet(random_state = 3)\n",
    "param_grid_en = {\n",
    "    'alpha': [0, 0.1, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],   # Penalty strength\n",
    "    'l1_ratio': [0, 0.1, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]  # Mixture of L1 (Lasso) and L2 (Ridge)\n",
    "}\n",
    "#Evaluate w/ 5-fold CV\n",
    "grid_search_en = GridSearchCV(en_model, param_grid_en, cv=5, scoring='neg_root_mean_squared_error')\n",
    "grid_search_en.fit(X_train_scaled, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa99698d-f0da-4e20-a30d-5b105fd883d3",
   "metadata": {},
   "source": [
    "#### Question 4 & Question 5\n",
    "Fit all the models you created in Question 3 to your folded data. Print the mean and standard errors of the performance metric ***root mean squared error (RMSE)*** for each model across folds.\n",
    "\n",
    "Decide which of the models has performed the best. Explain how/why you made this decision. Note that each value of the tuning parameter(s) is considered a different model; for instance, KNN with k = 4 is one model, KNN with K = 2 another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f630f5c-8137-4a4f-b7e2-14fe7a37917e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN Model: n_neighbors = 10\n",
      "Best Mean RMSE = 2.2799, Standard Deviation = 0.0818\n",
      "\n",
      "Linear Regression Model Results:\n",
      "Linear Regression: Mean RMSE = 2.2763147912114916, Standard Deviation = 0.12284541628270419\n",
      "Best RMSE: 2.276314754048024\n",
      "Standard Deviation of Best RMSE: 0.1228\n",
      "Best Hyperparameters: {'alpha': 0, 'l1_ratio': 0}\n"
     ]
    }
   ],
   "source": [
    "#KNN Model\n",
    "best_index_knn = grid_search_mae_knn.best_index_\n",
    "best_mean_rmse_knn = -grid_search_mae_knn.cv_results_['mean_test_score'][best_index_knn]\n",
    "best_std_rmse_knn = grid_search_mae_knn.cv_results_['std_test_score'][best_index_knn]\n",
    "best_params_knn = grid_search_mae_knn.best_params_\n",
    "print(f'Best KNN Model: n_neighbors = {best_params_knn[\"n_neighbors\"]}')\n",
    "print(f'Best Mean RMSE = {best_mean_rmse_knn:.4f}, Standard Deviation = {best_std_rmse_knn:.4f}')\n",
    "\n",
    "\n",
    "#LR Model\n",
    "print(\"\\nLinear Regression Model Results:\")\n",
    "lr_rmse_mean = np.mean(rmse_cv_scores_lr)\n",
    "lr_rmse_std = np.std(rmse_cv_scores_lr)\n",
    "print(f'Linear Regression: Mean RMSE = {lr_rmse_mean}, Standard Deviation = {lr_rmse_std}')\n",
    "\n",
    "#EN Model \n",
    "best_index = grid_search_en.best_index_\n",
    "best_score = -grid_search_en.best_score_\n",
    "best_std = grid_search_en.cv_results_['std_test_score'][best_index]\n",
    "best_params = grid_search_en.best_params_\n",
    "print(f\"Best RMSE: {best_score:}\")\n",
    "print(f\"Standard Deviation of Best RMSE: {best_std:.4f}\")\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b96503d-d0e0-4890-955a-08ec5fb57f1a",
   "metadata": {},
   "source": [
    "> While all scores were relatively similar, it seems the Elastic Net model performed the best of all the models with a mean RMSE score of **2.27631475** - barely beating out the Linear Regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1141affc-c702-4b62-921c-dd72d1a0984f",
   "metadata": {},
   "source": [
    "#### Question 6\n",
    "Fit your chosen model to the entire **training set**. \n",
    "\n",
    "Lastly, access the performance of your chosen model on your testing set. Compare your model's **testing** RMSE to its average RMSE across folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4944dae1-c950-47f9-a204-5bf5c91b61d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 2.1092843449499514\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "#Fit & predict test set\n",
    "best_model = ElasticNet(random_state = 3, alpha = 0, l1_ratio = 0)\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the RMSE on the test set\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f'Test RMSE: {test_rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b030c1-8be9-41d8-91e3-672bdb16439c",
   "metadata": {},
   "source": [
    "> After fitting the model to the entire training set and evaluating its performance on the testing dataset, the tuned Elastic Net model did slightly better than its average RMSE score across folds. With a RMSE score of **~2.109**, the model does well in predicting abalone age given the available features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19ad942-92f7-492b-842e-58118894319c",
   "metadata": {},
   "source": [
    "### Section 2: Classification (Titanic Survival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22a74d21-5a04-4760-ae2d-6531e3a44078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba5b9c6-4352-48bc-855f-02826beab8a6",
   "metadata": {},
   "source": [
    "#### Question 7\n",
    "Follow the instructions from Homework 3 to split the data set, stratifying on the outcome variable, survived. You can choose the proportions to split the data into. Use k-fold cross validation to create 5 folds from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad138c68-d36a-40f6-8d27-debb082cce2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in data \n",
    "titanic_data = pd.read_csv(\"data/titanic.csv\")\n",
    "X = titanic_data.drop(\"survived\", axis = 1)\n",
    "y = titanic_data[\"survived\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 3, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43dfcc9b-5e6c-44a0-a72b-41ee98be07d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "#Prep Train/test data for imputation \n",
    "train_data = pd.concat([X_train, y_train], axis = 1)\n",
    "test_data = pd.concat([X_test, y_test], axis = 1)\n",
    "\n",
    "#KKN imputer to handle missing age values\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "train_data[['age']] = imputer.fit_transform(train_data[['age']])\n",
    "test_data[['age']] = imputer.fit_transform(test_data[['age']])\n",
    "\n",
    "#Grabbing appropriate features and dummy coding categorical variables\n",
    "model_cols = ['survived','pclass', 'sex', 'age', 'sib_sp', 'parch', 'fare']\n",
    "train_data = train_data[model_cols]\n",
    "adj_train_data = pd.get_dummies(train_data, columns = ['pclass', 'sex'])\n",
    "test_data = test_data[model_cols]\n",
    "adj_test_data = pd.get_dummies(test_data, columns = ['pclass', 'sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba1992f-8e84-4289-8fb2-0375a193c7a5",
   "metadata": {},
   "source": [
    "#### Question 8\n",
    "Follow the instructions from Homework 3 - but this time, use SMOTE() to oversample such that there are equal proportions of the Yes and No levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3f313e5-fbbe-42ce-be5c-34ccc4ee9639",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate features and target variable for the training set\n",
    "X_train = adj_train_data.drop('survived', axis=1)\n",
    "y_train = adj_train_data['survived']\n",
    "\n",
    "#Separate features and target variable for the test set (not applying SMOTE to the test set)\n",
    "X_test = adj_test_data.drop('survived', axis=1)\n",
    "y_test = adj_test_data['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56c3afd2-31b7-4ec0-a61b-9361cf33d680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Yes': 439, 'No': 439})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "#Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=3)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "#Confirming oversample\n",
    "counter = Counter(y_train_smote)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d366e91-267f-44d7-8cbe-22038e0d20ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remapping survival 'Yes' indicates survival (1) and 'No' indicates non-survival (0)\n",
    "y_train_smote = y_train_smote.map({'Yes': 1, 'No': 0})\n",
    "y_test = y_test.map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19612d1c-fec0-48ce-a9e8-76cb62188016",
   "metadata": {},
   "source": [
    "#### Question 9 & 10\n",
    "Set up the three models:\n",
    "- K-Nearest neighbors with the KNeighborsRegressor function, tuning n_neighbors\n",
    "- logistic regression\n",
    "- elastic net **logistic** regression, tuning penalty and mixture\n",
    "\n",
    "Set up the grids, etc. the same way you did in Question 3. Note that you can use the same grids of parameter values without having to recreate them. Fit all the models you created in Question 9 to your folded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2f31aa6-18e3-4aed-98cb-743e3fd1ee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Define model & tuning grid\n",
    "knn_model = KNeighborsClassifier()\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': range(1,11)\n",
    "}\n",
    "#Evaluate w/ 5-fold CV\n",
    "grid_search_mae_knn = GridSearchCV(knn_model, param_grid_knn, cv = 5, scoring = 'roc_auc')\n",
    "grid_search_mae_knn.fit(X_train_smote, y_train_smote);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e57bda5-91b9-44d3-a776-63de4be4d88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Define logistic regression model \n",
    "logreg_model = LogisticRegression(random_state=3)\n",
    "\n",
    "#Evaluate with 5-fold cross-validation using ROC AUC as the scoring metric\n",
    "auc_cv_scores_logreg = cross_val_score(logreg_model, X_train_smote, y_train_smote, cv=5, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "25f0e6d1-3278-43d4-85f1-83b93c6d537d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "en_logreg_model = LogisticRegression(penalty='elasticnet', solver='saga', random_state=3)\n",
    "param_grid_en = {\n",
    "    'C': [0, 0.1, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],  \n",
    "    'l1_ratio': [0, 0.1, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]  #Mixture of L1 (Lasso) and L2 (Ridge) where l1 = 0 is only ridge\n",
    "}\n",
    "\n",
    "grid_search_en_logreg = GridSearchCV(en_logreg_model, param_grid_en, cv=5, scoring = 'roc_auc')\n",
    "grid_search_en_logreg.fit(X_train_smote, y_train_smote);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f25427-c13e-4aeb-95b4-30f11cf9b814",
   "metadata": {},
   "source": [
    "#### Question 11\n",
    "Print the means and standard errors of the performance metric: area under the ROC curve for each model across folds.\n",
    "\n",
    "Decide which of the models has performed the best. Explain how/why you made this decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "70d16038-2f32-4db0-a43f-9f04ba266ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN Model: n_neighbors = 4\n",
      "Best Mean ROC AUC = 0.8127, Standard Deviation = 0.0476\n",
      "Logistic Regression: Mean ROC AUC = 0.8672, Standard Deviation = 0.0541\n",
      "Best ElasticNet Logistic Regression Model: C = 0.3, l1_ratio = 0\n",
      "Best Mean ROC AUC = 0.7492, Standard Deviation = 0.0260\n"
     ]
    }
   ],
   "source": [
    "#KNeighbors Classifier Model\n",
    "best_index_knn = grid_search_mae_knn.best_index_\n",
    "best_mean_auc_knn = grid_search_mae_knn.cv_results_['mean_test_score'][best_index_knn]\n",
    "best_std_auc_knn = grid_search_mae_knn.cv_results_['std_test_score'][best_index_knn]\n",
    "best_params_knn = grid_search_mae_knn.best_params_\n",
    "print(f'Best KNN Model: n_neighbors = {best_params_knn[\"n_neighbors\"]}')\n",
    "print(f'Best Mean ROC AUC = {best_mean_auc_knn:.4f}, Standard Deviation = {best_std_auc_knn:.4f}')\n",
    "\n",
    "#Logistic Regression model\n",
    "mean_auc_logreg = np.mean(auc_cv_scores_logreg)\n",
    "std_auc_logreg = np.std(auc_cv_scores_logreg)\n",
    "print(f'Logistic Regression: Mean ROC AUC = {mean_auc_logreg:.4f}, Standard Deviation = {std_auc_logreg:.4f}')\n",
    "\n",
    "#Elastic Net Logistic Regression model\n",
    "best_index_en_logreg = grid_search_en_logreg.best_index_\n",
    "best_mean_auc_en_logreg = grid_search_en_logreg.cv_results_['mean_test_score'][best_index_en_logreg]\n",
    "best_std_auc_en_logreg = grid_search_en_logreg.cv_results_['std_test_score'][best_index_en_logreg]\n",
    "best_params_en_logreg = grid_search_en_logreg.best_params_\n",
    "print(f'Best ElasticNet Logistic Regression Model: C = {best_params_en_logreg[\"C\"]}, l1_ratio = {best_params_en_logreg[\"l1_ratio\"]}')\n",
    "print(f'Best Mean ROC AUC = {best_mean_auc_en_logreg:.4f}, Standard Deviation = {best_std_auc_en_logreg:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d633990-12b7-4c48-bfaa-075e8b593b9b",
   "metadata": {},
   "source": [
    "> After evaluating the models based on the mean ROC AUC score and its standard deviation, the best performing model was the Logistic Regression model with a mean ROC AUC score of .8672 and sd of .0541. This means that the model distinguishes between the positive and negative classes with a relatively high degree of accuracy and consistency. While it does not have the lowest ROC AUC std, it's difference is negligible in the context of the problem and should still generalize well to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9150c1a9-deba-4280-b0bb-a783edd6b482",
   "metadata": {},
   "source": [
    "#### Question 12\n",
    "Fit your chosen model to the entire **training set.** Assess the performance of your chosen model on your **testing set.** Compare your model's **testing** ROC AUC to its average ROC AUC across folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f8b2789-9a87-45c3-b913-baedd4523b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC on the Test set: 0.900000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "best_model_classifier = LogisticRegression(random_state=3)\n",
    "best_model_classifier.fit(X_train_smote, y_train_smote)\n",
    "best_pred_proba = best_model_classifier.predict_proba(X_test)[:,1]\n",
    "roc_auc_test = roc_auc_score(y_test, best_pred_proba)\n",
    "print(f'ROC AUC on the Test set: {roc_auc_test:f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a75c3b-281a-4186-a405-19507f9a44bf",
   "metadata": {},
   "source": [
    "> The Logistic Regression model performed well on the test set with a ROC AUC score of 0.9000, which is slightly higher than its average cross-validated performance of 0.8672. The consistency in performance between cross-validation and the test set indicates that the model generalizes well to unseen data and has not overfit the training data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
