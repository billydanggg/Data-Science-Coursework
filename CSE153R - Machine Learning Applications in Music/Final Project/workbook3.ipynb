{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9Ecs-6yxiud"
   },
   "source": [
    "# Install and load required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 4702,
     "status": "ok",
     "timestamp": 1745877899137,
     "user": {
      "displayName": "Jingyue Huang",
      "userId": "11611851786193480123"
     },
     "user_tz": 420
    },
    "id": "g4VJpcg4xiue"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "from typing import List\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import choice\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from symusic import Score\n",
    "from miditok import REMI, TokenizerConfig\n",
    "from miditok.pytorch_data import DatasetMIDI, DataCollator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1745878020365,
     "user": {
      "displayName": "Jingyue Huang",
      "userId": "11611851786193480123"
     },
     "user_tz": 420
    },
    "id": "58o78Ax9xiug"
   },
   "outputs": [],
   "source": [
    "train_files = glob.glob(\"./data/train/*.mid\")\n",
    "test_files = glob.glob(\"./data/test/*.mid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VBN0aYQ3TsIj"
   },
   "source": [
    "# RNN for MIDI generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2w9rx8CX7SY"
   },
   "source": [
    "## A New Dataset for batch inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "PtVV2bvtkNZQ"
   },
   "outputs": [],
   "source": [
    "from miditok.pytorch_data import DatasetMIDI, DataCollator\n",
    "\n",
    "tokenizer = REMI()  # using defaults parameters (constants.py)\n",
    "train_dataset = DatasetMIDI(\n",
    "    files_paths=train_files,\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_len=1024,\n",
    "    bos_token_id=tokenizer[\"BOS_None\"],\n",
    "    eos_token_id=tokenizer[\"EOS_None\"],\n",
    ")\n",
    "test_dataset = DatasetMIDI(\n",
    "    files_paths=test_files,\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_len=1024,\n",
    "    bos_token_id=tokenizer[\"BOS_None\"],\n",
    "    eos_token_id=tokenizer[\"EOS_None\"],\n",
    ")\n",
    "collator = DataCollator(tokenizer.pad_token_id)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collator)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1745713128943,
     "user": {
      "displayName": "Jingyue Huang",
      "userId": "11611851786193480123"
     },
     "user_tz": -120
    },
    "id": "eN62DQ2MbnvF",
    "outputId": "23e7fece-e34c-4065-ac0a-2c266e28ea59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VR7hZbrLTyu1"
   },
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "wfddI849TzsN"
   },
   "outputs": [],
   "source": [
    "class MusicRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n",
    "        super(MusicRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        # x: (batch_size, seq_length)\n",
    "        x = self.embedding(x)  # (batch_size, seq_length, embedding_dim)\n",
    "        out, hidden = self.rnn(x, hidden)  # out: (batch_size, seq_length, hidden_dim)\n",
    "        out = self.fc(out)  # (batch_size, seq_length, vocab_size)\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVSszSART00u"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 169117,
     "status": "ok",
     "timestamp": 1745714014906,
     "user": {
      "displayName": "Jingyue Huang",
      "userId": "11611851786193480123"
     },
     "user_tz": -120
    },
    "id": "-OelLTyQT3gY",
    "outputId": "f3ac99f9-eda4-4f20-c319-7746797ab340"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Train Loss: 3.8777 | Val Loss: 2.6451\n",
      "Epoch 2/20 | Train Loss: 2.7362 | Val Loss: 2.1661\n",
      "Epoch 3/20 | Train Loss: 2.4909 | Val Loss: 2.0267\n",
      "Epoch 4/20 | Train Loss: 2.3528 | Val Loss: 1.9302\n",
      "Epoch 5/20 | Train Loss: 2.2377 | Val Loss: 1.8431\n",
      "Epoch 6/20 | Train Loss: 2.1123 | Val Loss: 1.6932\n",
      "Epoch 7/20 | Train Loss: 1.9645 | Val Loss: 1.5815\n",
      "Epoch 8/20 | Train Loss: 1.8526 | Val Loss: 1.5218\n",
      "Epoch 9/20 | Train Loss: 1.7708 | Val Loss: 1.4791\n",
      "Epoch 10/20 | Train Loss: 1.6985 | Val Loss: 1.4198\n",
      "Epoch 11/20 | Train Loss: 1.6344 | Val Loss: 1.3965\n",
      "Epoch 12/20 | Train Loss: 1.5806 | Val Loss: 1.3807\n",
      "Epoch 13/20 | Train Loss: 1.5106 | Val Loss: 1.3099\n",
      "Epoch 14/20 | Train Loss: 1.4379 | Val Loss: 1.2888\n",
      "Epoch 15/20 | Train Loss: 1.3872 | Val Loss: 1.2589\n",
      "Epoch 16/20 | Train Loss: 1.3240 | Val Loss: 1.2357\n",
      "Epoch 17/20 | Train Loss: 1.2792 | Val Loss: 1.2254\n",
      "Epoch 18/20 | Train Loss: 1.2526 | Val Loss: 1.2113\n",
      "Epoch 19/20 | Train Loss: 1.1841 | Val Loss: 1.2201\n",
      "Epoch 20/20 | Train Loss: 1.1305 | Val Loss: 1.2107\n"
     ]
    }
   ],
   "source": [
    "def train(model, train_loader, val_loader, vocab_size, num_epochs=20, lr=0.001, device='cpu'):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # --------- Training ---------\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            batch = batch['input_ids'].to(device)  # (batch_size, seq_length)\n",
    "\n",
    "            inputs = batch[:, :-1]\n",
    "            targets = batch[:, 1:]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs, _ = model(inputs)\n",
    "            outputs = outputs.reshape(-1, vocab_size)\n",
    "            targets = targets.reshape(-1)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "        # --------- Validation ---------\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch = batch['input_ids'].to(device)\n",
    "\n",
    "                inputs = batch[:, :-1]\n",
    "                targets = batch[:, 1:]\n",
    "\n",
    "                outputs, _ = model(inputs)\n",
    "                outputs = outputs.reshape(-1, vocab_size)\n",
    "                targets = targets.reshape(-1)\n",
    "\n",
    "                loss = criterion(outputs, targets)\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    vocab_size = tokenizer.vocab_size\n",
    "    embedding_dim = 256\n",
    "    hidden_dim = 512\n",
    "    num_layers = 2\n",
    "\n",
    "    model = MusicRNN(vocab_size, embedding_dim, hidden_dim, num_layers)\n",
    "    train(model, train_loader, test_loader, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0NQxTiiT3-t"
   },
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 905,
     "status": "ok",
     "timestamp": 1745714020696,
     "user": {
      "displayName": "Jingyue Huang",
      "userId": "11611851786193480123"
     },
     "user_tz": -120
    },
    "id": "aqGTcuhtT7c6",
    "outputId": "89733c4f-9c1d-439a-f6cf-d96f8ed4d95b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated token sequence:\n",
      "[1, 4, 189, 49, 113, 128, 53, 113, 128, 41, 113, 128, 193, 53, 111, 128, 58, 111, 128, 197, 58, 113, 128, 61, 113, 128, 58, 113, 128, 201, 46, 112, 128, 53, 112, 128, 205, 56, 113, 126, 52, 112, 128, 207, 61, 114, 125, 209, 53, 112, 128, 63, 112, 128, 211, 56, 110, 126, 213, 54, 111, 128, 56, 111, 128, 217, 51, 110, 126, 56, 110, 126, 219, 52, 110, 126, 4, 189, 56, 110, 140, 51, 111, 126, 191, 49, 109, 126, 193, 54, 112, 126, 195, 54, 111, 126, 197, 51, 110, 126, 42, 110, 128, 199, 56, 111, 126, 201, 56, 111, 126, 46, 111, 128, 203, 56, 111, 126, 205, 56, 114, 126, 61, 114, 126, 207, 61, 112, 126, 209, 58, 111, 126, 39, 111, 128, 211, 65, 113, 126, 213, 63, 114, 126, 217, 63, 112, 126, 51, 112, 128, 219, 56, 110, 126, 4, 189, 68, 110, 128, 63, 110, 128, 193, 58, 110, 126, 195, 56, 110, 126, 197, 53, 110, 132, 58, 110, 132, 37, 110, 126, 199, 39, 112, 126, 201, 41, 110, 126, 203, 41, 111, 126, 205, 51, 112, 126, 68, 112, 126, 35, 111, 128, 207, 58, 110, 126, 209, 56, 110, 128, 44, 111, 132, 213, 51, 110, 128, 48, 111, 128, 217, 49, 109, 128, 53, 109, 128, 43, 111, 126, 219, 44, 111, 126, 4, 189, 53, 111, 128, 46, 111, 128, 191, 53, 110, 126, 193, 51, 109, 126, 195, 51, 110, 126, 197, 51, 110, 128, 53, 110, 128, 201, 53, 112, 126, 37, 110, 128, 203, 53, 110, 126, 205, 44, 112, 140, 49, 112, 140, 209, 39, 111, 128, 213, 27, 110, 128, 217, 32, 110, 128, 4, 189, 32, 111, 128, 193, 41, 112, 126, 195, 39, 113, 126, 197, 34, 111, 126, 201, 39, 114, 126, 46, 114, 126, 205, 27, 111, 128, 209, 39, 112, 126, 211, 36, 111, 126, 213, 34, 111, 128, 217, 34, 112, 128, 41, 112, 128, 4, 189, 46, 113, 130, 37, 113, 128, 193, 34, 111, 128, 195, 46, 113, 126, 39, 111, 126, 197, 51, 112, 128, 34, 110, 126, 199, 34, 110, 126, 201, 53, 111, 128, 61, 111, 128, 37, 113, 128, 205, 41, 111, 134, 46, 111, 140, 209, 44, 112, 128, 211, 41, 112, 126, 213, 37, 111, 128, 217, 37, 114, 128, 41, 114, 128, 220, 44, 112, 142, 4, 189, 41, 114, 140, 193, 46, 111, 126, 195, 46, 112, 126, 197, 46, 112, 128, 201, 44, 111, 126, 203, 46, 111, 130, 205, 49, 113, 128, 37, 112, 126, 207, 39, 111, 126, 209, 46, 111, 130, 51, 111, 149, 206, 37, 112, 132, 211, 41, 112, 126, 213, 37, 111, 126, 215, 37, 111, 126, 217, 37, 109, 126, 219, 32, 109, 126, 4, 189, 51, 113, 128, 58, 113, 128, 37, 112, 128, 193, 58, 111, 128, 39, 112, 128, 41, 112, 126, 195, 56, 111, 126, 197, 58, 111, 128, 39, 111, 128, 201, 53, 110, 128, 39, 111, 126, 46, 111, 126, 205, 56, 112, 128, 34, 111, 132, 209, 58, 111, 126, 211, 55, 111, 126, 213, 51, 110, 128, 57, 111, 128, 46, 114, 128, 217, 56, 111, 128, 41, 112, 128, 4, 189, 56, 112, 132, 41, 112, 128, 193, 42, 111, 128, 197, 54, 111, 128, 39, 111, 128, 201, 53, 111, 126, 37, 112, 128, 44, 112, 128, 203, 53, 111, 126, 205, 51, 110, 128, 207, 56, 112, 126, 209, 53, 111, 126, 39, 112, 128, 211, 53, 109, 126, 213, 49, 109, 132, 39, 113, 128, 217, 39, 112, 128, 4, 189, 46, 110, 132, 193, 39, 112, 128, 41, 112, 128, 197, 44, 111, 128, 48, 111, 128, 53, 111, 128, 37, 111, 128, 201, 34, 111, 126, 203, 41, 112, 126, 205, 43, 111, 128, 49, 111, 128, 32, 111, 128, 209, 49, 112, 128, 54, 112, 128, 37, 111, 126, 211, 37, 110, 126, 213, 35, 111, 128, 32, 111, 128, 217, 44, 110, 128, 31, 111, 126, 219, 34, 109, 126, 4, 189, 44, 112, 140, 193, 49, 112, 126, 36, 111, 126, 195, 36, 111, 126, 197, 41, 112, 128, 201, 36, 111, 128, 205, 53, 113, 128, 58, 113, 128, 44, 113, 140, 209, 58, 112, 128, 213, 56, 111, 128, 217, 49, 110, 128, 53, 110, 128, 4, 189, 53, 114, 128, 56, 114, 128, 41, 112, 128, 193, 51, 111, 134, 54, 111, 139, 58, 111, 138, 195, 41, 112, 126, 197, 41, 111, 126, 199, 44, 113, 126, 201, 37, 111, 126, 203, 39, 111, 126, 205, 46, 113, 140, 58, 113, 140, 37, 111, 128, 209, 37, 111, 126, 211, 32, 111, 126, 213, 32, 110, 128, 217, 39, 111, 128, 4, 189, 54, 112, 128, 61, 112, 128, 27, 111, 128, 193, 63, 113, 126, 34, 111, 128, 207, 35, 111, 126, 193, 44, 111, 126, 48, 111, 126, 54, 111, 126, 34, 111, 128, 195, 58, 111, 126, 197, 51, 110, 128, 60, 110, 128, 34, 111, 128, 201, 49, 110, 128, 53, 110, 128, 36, 111, 128, 205, 41, 110, 140, 46, 110, 140, 53, 110, 140, 29, 110, 126, 191, 29, 110, 126, 209, 29, 111, 126, 219, 32, 112, 126, 213, 37, 113, 132, 219, 37, 111, 126, 4, 189, 34, 111, 128, 193, 31, 111, 128, 197, 37, 111, 128, 201, 37, 111, 126, 203, 44, 113, 126, 205, 49, 113, 132, 58, 113, 132, 37, 112, 136, 209, 49, 111, 128, 213, 51, 111, 128, 217, 46, 111, 128, 53, 111, 128, 39, 112, 126, 219, 44, 112, 126, 4, 189, 49, 113, 128, 53, 113, 128, 56, 113, 128, 37, 111, 132, 193, 51, 111, 128, 70, 111, 128, 197, 51, 113, 136, 63, 111, 136, 39, 112, 128, 201, 41, 111, 128, 205, 56, 113, 128, 51, 113, 128, 56, 113, 128, 209, 51, 111, 128, 56, 111, 128, 37, 111, 128, 213, 44, 110, 132, 49, 110, 132, 54, 110, 132, 42, 113, 132, 4, 189, 49, 113, 128, 56, 113, 128]\n"
     ]
    }
   ],
   "source": [
    "def sample(model, start_token, max_length=100, temperature=1.0, device='cpu'):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    generated = [start_token]\n",
    "    input_token = torch.tensor([[start_token]], device=device)  # (1, 1)\n",
    "\n",
    "    hidden = None\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        output, hidden = model(input_token, hidden)  # output: (1, 1, vocab_size)\n",
    "        output = output[:, -1, :]  # take the last output\n",
    "        output = output / temperature  # adjust randomness\n",
    "\n",
    "        probs = F.softmax(output, dim=-1)  # (1, vocab_size)\n",
    "        next_token = torch.multinomial(probs, num_samples=1).item()\n",
    "        generated.append(next_token)\n",
    "        if next_token == 2 or next_token == 0: # reach end of sequence\n",
    "          break\n",
    "\n",
    "        input_token = torch.tensor([[next_token]], device=device)\n",
    "\n",
    "    return generated\n",
    "\n",
    "start_token = tokenizer.special_tokens_ids[1]\n",
    "generated_sequence = sample(model, start_token, max_length=1024)\n",
    "\n",
    "print(\"Generated token sequence:\")\n",
    "print(generated_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Pm3UPSBQqjU2"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "File not found file (error:13): rnn.mid",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m fs \u001b[38;5;241m=\u001b[39m FluidSynth(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFluidR3Mono_GM.sf3\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# Initialize FluidSynth\u001b[39;00m\n\u001b[0;32m      5\u001b[0m output_score \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode([generated_sequence])\n\u001b[1;32m----> 6\u001b[0m output_score\u001b[38;5;241m.\u001b[39mdump_midi(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrnn.mid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m fs\u001b[38;5;241m.\u001b[39mmidi_to_audio(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrnn.mid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrnn.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m display(Audio(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrnn.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: File not found file (error:13): rnn.mid"
     ]
    }
   ],
   "source": [
    "from midi2audio import FluidSynth # Import library\n",
    "from IPython.display import Audio, display\n",
    "fs = FluidSynth(\"FluidR3Mono_GM.sf3\") # Initialize FluidSynth\n",
    "\n",
    "output_score = tokenizer.decode([generated_sequence])\n",
    "output_score.dump_midi(f\"rnn.mid\")\n",
    "fs.midi_to_audio(\"rnn.mid\", \"rnn.wav\")\n",
    "display(Audio(\"rnn.wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
